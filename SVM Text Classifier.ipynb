{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed1222c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0b2dd508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_df = pd.read_excel('glossary/deportes.xlsx', names = ['word', 'rank'] , usecols = [0,1])\n",
    "sport_df['class'] = 0\n",
    "\n",
    "health_df = pd.read_excel('glossary/salud.xlsx', names = ['word', 'rank'] , usecols = [0,1])\n",
    "health_df['class'] = 1\n",
    "\n",
    "politics_df = pd.read_excel('glossary/politica.xlsx', names = ['word', 'rank'] , usecols = [0,1])\n",
    "politics_df['class'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9e535f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports Glossary Size: 5961\n",
      "Health Glossary Size: 4779\n",
      "Politics Glossary Size: 6489\n",
      "Total Glossary Size: 17229\n"
     ]
    }
   ],
   "source": [
    "print('Sports Glossary Size:', len(sport_df))\n",
    "print('Health Glossary Size:', len(health_df))\n",
    "print('Politics Glossary Size:', len(politics_df))\n",
    "\n",
    "print('Total Glossary Size:', (len(politics_df) + len(health_df) + len(sport_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "942386a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossariy_df = pd.concat([sport_df, health_df, politics_df])\n",
    "glossariy_df = glossariy_df.drop_duplicates(subset='word', keep = False)\n",
    "glossariy_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5ed951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports Glossary Size: 4621\n",
      "Health Glossary Size: 3473\n",
      "Politics Glossary Size: 4906\n",
      "Total Glossary Size: 13000\n"
     ]
    }
   ],
   "source": [
    "print('Sports Glossary Size:', len(glossariy_df[glossariy_df['class'] == 0]))\n",
    "print('Health Glossary Size:', len(glossariy_df[glossariy_df['class'] == 1]))\n",
    "print('Politics Glossary Size:', len(glossariy_df[glossariy_df['class'] == 2]))\n",
    "\n",
    "print('Total Glossary Size:', len(glosariy_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fab30a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [glossariy_df[glossariy_df['class'] == 0][:100], glossariy_df[glossariy_df['class'] == 1][:100], glossariy_df[glossariy_df['class'] == 2][:100]]\n",
    "\n",
    "glossariy_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3ab97d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>rank</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>equipos</td>\n",
       "      <td>0.733216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juegos</td>\n",
       "      <td>0.648853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arco</td>\n",
       "      <td>0.513120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiro</td>\n",
       "      <td>0.476046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>federación</td>\n",
       "      <td>0.452823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>militares</td>\n",
       "      <td>0.191268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>responde</td>\n",
       "      <td>0.189518</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>calvo</td>\n",
       "      <td>0.188902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>carmen calvo</td>\n",
       "      <td>0.188902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>afirmado</td>\n",
       "      <td>0.188527</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word      rank  class\n",
       "0         equipos  0.733216      0\n",
       "1          juegos  0.648853      0\n",
       "2            arco  0.513120      0\n",
       "3            tiro  0.476046      0\n",
       "4      federación  0.452823      0\n",
       "..            ...       ...    ...\n",
       "295     militares  0.191268      2\n",
       "296      responde  0.189518      2\n",
       "297         calvo  0.188902      2\n",
       "298  carmen calvo  0.188902      2\n",
       "299      afirmado  0.188527      2\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossariy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aab33fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "myvocabulary = list(glossariy_df['word'])\n",
    "\n",
    "tfidf_global = TfidfVectorizer(input='filename', vocabulary = myvocabulary, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cb8db526",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tfidf_global.fit_transform(['processed-corpus/Deportes_1.txt', 'processed-corpus/Salud_1.txt'])\n",
    "x_train = x_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64e381ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equipos</th>\n",
       "      <th>juegos</th>\n",
       "      <th>arco</th>\n",
       "      <th>tiro</th>\n",
       "      <th>federación</th>\n",
       "      <th>balón</th>\n",
       "      <th>oro</th>\n",
       "      <th>set</th>\n",
       "      <th>brown</th>\n",
       "      <th>serbia</th>\n",
       "      <th>...</th>\n",
       "      <th>franja</th>\n",
       "      <th>socialista</th>\n",
       "      <th>fernández</th>\n",
       "      <th>ámbito</th>\n",
       "      <th>judicial</th>\n",
       "      <th>militares</th>\n",
       "      <th>responde</th>\n",
       "      <th>calvo</th>\n",
       "      <th>carmen calvo</th>\n",
       "      <th>afirmado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   equipos  juegos  arco  tiro  federación  balón  oro  set  brown  serbia  \\\n",
       "0      0.0     0.0   0.0   0.0         0.0    0.0  0.0  0.0    0.0     0.0   \n",
       "1      0.0     0.0   0.0   0.0         0.0    0.0  0.0  0.0    0.0     0.0   \n",
       "\n",
       "   ...  franja  socialista  fernández  ámbito  judicial  militares  responde  \\\n",
       "0  ...     0.0         0.0        0.0     0.0       0.0        0.0       0.0   \n",
       "1  ...     0.0         0.0        0.0     0.0       0.0        0.0       0.0   \n",
       "\n",
       "   calvo  carmen calvo  afirmado  \n",
       "0    0.0           0.0       0.0  \n",
       "1    0.0           0.0       0.0  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train = pd.DataFrame(x_train)\n",
    "df_x_train.columns = myvocabulary\n",
    "df_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa0e9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tfidf_global.transform(['processed-corpus/Deportes_2.txt'])\n",
    "x_test = x_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64bc32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame({'Class':[0, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7604deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e559b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_y.values\n",
    "x_train = df_x_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "426adfaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 6 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [137], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m RepeatedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m((mean(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_precision_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m])),\u001b[38;5;241m3\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m| Desviación típica: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m( \u001b[38;5;28mround\u001b[39m( std(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_precision_macro\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m3\u001b[39m)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 6 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=2, n_repeats=3, random_state=1)\n",
    "metrics = cross_validate(model, x_train, y_train, scoring=['precision_macro', 'recall_macro'], cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Precision: ', str(round((mean(metrics[\"test_precision_macro\"])),3)), '| Desviación típica: ', str( round( std(metrics[\"test_precision_macro\"]), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "966ff540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdrianAD\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clasificador = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo', probability=True).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d76c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = clasificador.predict_proba(x_test)\n",
    "predicciones_rounded = [np.round(x,3) for x in predicciones]\n",
    "\n",
    "df_predicciones = pd.DataFrame(predicciones_rounded)\n",
    "df_predicciones.columns=['Salud', 'Politica', 'Deportes']\n",
    "df_predicciones.index.name = 'Documento'\n",
    "df_predicciones['Clase_real'] = y_test\n",
    "df_predicciones.to_excel('/content/drive/MyDrive/Ignieria_Linguistica/modelo_SVM_glosario/predicciones.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
